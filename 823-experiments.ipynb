{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport imblearn\ndf = pd.read_csv(\"../input/mimic3extracted/mimic-iii-823.csv\")\n#dropped DOB, and ADMIT_TIME since info in other variables\n#dropped diagnosis since to many variables when onehot encoded, partial info encoded in other variables\ndf = df.drop(['DOB', 'ADMIT_TIME', \"DIAGNOSIS\", 'HADM_ID', 'SUBJECT_ID'], axis=1)\ndf = pd.get_dummies(df, columns=['GENDER'], prefix=\"gender_\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['ADMISSION_TYPE'], prefix=\"admit_type\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['ADMISSION_LOCATION'], prefix=\"admit_location\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['INSURANCE'], prefix=\"insurance\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['LANGUAGE'], prefix=\"LANGUAGE_\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['RELIGION'], prefix=\"RELIGION_\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['MARITAL_STATUS'], prefix=\"MARITAL_STATUS_\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['ETHNICITY'], prefix=\"ETHNICITY_\")\nprint(df.shape)\ndf = pd.get_dummies(df, columns=['month_since_last_visit'], prefix=\"month_since_last_visit\")\nprint(df.shape)\n\n\ndf['year_since_last_visit'] = df['year_since_last_visit'].fillna(df['year_since_last_visit'].max())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-24T19:10:16.995049Z","iopub.execute_input":"2022-04-24T19:10:16.995331Z","iopub.status.idle":"2022-04-24T19:10:17.304487Z","shell.execute_reply.started":"2022-04-24T19:10:16.995303Z","shell.execute_reply":"2022-04-24T19:10:17.303526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"HOSPITAL_EXPIRE_FLAG\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:42:26.602781Z","iopub.execute_input":"2022-04-23T17:42:26.603121Z","iopub.status.idle":"2022-04-23T17:42:26.615901Z","shell.execute_reply.started":"2022-04-23T17:42:26.603076Z","shell.execute_reply":"2022-04-23T17:42:26.614857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfor element in df.select_dtypes(include=['int64']).columns:\n    df[[element]] = scaler.fit_transform(df[[element]])\n\nfor element in df.select_dtypes(include=['float64']).columns:\n    df[[element]] = scaler.fit_transform(df[[element]])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:10:20.956128Z","iopub.execute_input":"2022-04-24T19:10:20.956793Z","iopub.status.idle":"2022-04-24T19:10:24.271158Z","shell.execute_reply.started":"2022-04-24T19:10:20.956751Z","shell.execute_reply":"2022-04-24T19:10:24.270282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset SMOTE\n\nfrom matplotlib import pyplot\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\ntop_AUC = 0\nbest_model = None\n# define dataset\nX = df.drop([\"HOSPITAL_EXPIRE_FLAG\"], axis=1)\ny = df[\"HOSPITAL_EXPIRE_FLAG\"]\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state = 1)\n# define pipeline\nk = 1\nprint(\"random forest results\")\nwhile k < 100:\n    # evaluate pipeline\n    model = RandomForestClassifier(max_depth=k, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    if roc_auc_score(y_test, y_pred) > top_AUC:\n        top_AUC = roc_auc_score(y_test, y_pred)\n        best_model = model\n\n\"\"\"print(\"SVM results\")\nk = 1\nwhile k < 8:\n    # evaluate pipeline\n    model = SVC(degree=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    if roc_auc_score(y_test, y_pred) > top_AUC:\n        top_AUC = roc_auc_score(y_test, y_pred)\n        best_model = model\n    \nprint(\"GradientBoostingClassifier results\")\nk = 1\nwhile k < 7:\n    # evaluate pipeline\n    model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=k, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    if roc_auc_score(y_test, y_pred) > top_AUC:\n        top_AUC = roc_auc_score(y_test, y_pred)\n        best_model = model\n    \nprint(\"AdaBoostClassifier results\")\nk = 15\nwhile k < 10:\n    # evaluate pipeline\n    model = AdaBoostClassifier(n_estimators=k*25, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    if roc_auc_score(y_test, y_pred) > top_AUC:\n        top_AUC = roc_auc_score(y_test, y_pred)\n        best_model = model\n    \nprint(\"Knn results\")\nk = 3\nwhile k < 10:\n    # evaluate pipeline\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    if roc_auc_score(y_test, y_pred) > top_AUC:\n        top_AUC = roc_auc_score(y_test, y_pred)\n        best_model = model\n    \nprint(\"MLP results\")\nk = 1\nwhile k < 5:\n    # evaluate pipeline\n    model = MLPClassifier(solver='adam', hidden_layer_sizes=(50*k,50*k, 50*k), random_state=1)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    if roc_auc_score(y_test, y_pred) > top_AUC:\n        top_AUC = roc_auc_score(y_test, y_pred)\n        best_model = model\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:10:45.638084Z","iopub.execute_input":"2022-04-24T19:10:45.638361Z","iopub.status.idle":"2022-04-24T19:15:05.636083Z","shell.execute_reply.started":"2022-04-24T19:10:45.638335Z","shell.execute_reply":"2022-04-24T19:15:05.635214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(top_AUC)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:45:29.223635Z","iopub.execute_input":"2022-04-24T17:45:29.224041Z","iopub.status.idle":"2022-04-24T17:45:29.229175Z","shell.execute_reply.started":"2022-04-24T17:45:29.223996Z","shell.execute_reply":"2022-04-24T17:45:29.228067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install interpret","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:05:45.639848Z","iopub.execute_input":"2022-04-24T19:05:45.640332Z","iopub.status.idle":"2022-04-24T19:06:08.246295Z","shell.execute_reply.started":"2022-04-24T19:05:45.64029Z","shell.execute_reply":"2022-04-24T19:06:08.245107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from interpret import set_visualize_provider\nfrom interpret.provider import InlineProvider\nset_visualize_provider(InlineProvider())\n\nfrom interpret.glassbox import ExplainableBoostingClassifier\nfrom interpret import show\n\nebm = ExplainableBoostingClassifier(random_state=1)\nebm.fit(X_train, y_train)\ny_pred = ebm.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nebm_global = ebm.explain_global()\nshow(ebm_global)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:50:02.353601Z","iopub.execute_input":"2022-04-23T17:50:02.354317Z","iopub.status.idle":"2022-04-23T17:50:21.709168Z","shell.execute_reply.started":"2022-04-23T17:50:02.354273Z","shell.execute_reply":"2022-04-23T17:50:21.705523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ebm_local = ebm.explain_local(X_test[:5], y_test[:5])\nshow(ebm_local)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.08502Z","iopub.status.idle":"2022-04-22T14:57:15.085716Z","shell.execute_reply.started":"2022-04-22T14:57:15.085396Z","shell.execute_reply":"2022-04-22T14:57:15.085427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pygam\n!pip install flit","metadata":{"execution":{"iopub.status.busy":"2022-04-24T15:40:12.046597Z","iopub.execute_input":"2022-04-24T15:40:12.04691Z","iopub.status.idle":"2022-04-24T15:40:36.694261Z","shell.execute_reply.started":"2022-04-24T15:40:12.046864Z","shell.execute_reply":"2022-04-24T15:40:36.692973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pygam import LinearGAM, s, f","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.089481Z","iopub.status.idle":"2022-04-22T14:57:15.08998Z","shell.execute_reply.started":"2022-04-22T14:57:15.089719Z","shell.execute_reply":"2022-04-22T14:57:15.089746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pygam import LinearGAM, s, f\n\ngam = LinearGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.091457Z","iopub.status.idle":"2022-04-22T14:57:15.091947Z","shell.execute_reply.started":"2022-04-22T14:57:15.091672Z","shell.execute_reply":"2022-04-22T14:57:15.091714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gam = LinearGAM(s(0) + s(1) + s(2) + s(3) + f(4)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.093413Z","iopub.status.idle":"2022-04-22T14:57:15.093901Z","shell.execute_reply.started":"2022-04-22T14:57:15.093624Z","shell.execute_reply":"2022-04-22T14:57:15.09365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gam = LinearGAM(s(0) + f(1)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.095455Z","iopub.status.idle":"2022-04-22T14:57:15.09595Z","shell.execute_reply.started":"2022-04-22T14:57:15.095668Z","shell.execute_reply":"2022-04-22T14:57:15.095716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gam = LinearGAM(s(0) + s(1) + f(2) + f(3)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.097397Z","iopub.status.idle":"2022-04-22T14:57:15.097902Z","shell.execute_reply.started":"2022-04-22T14:57:15.097617Z","shell.execute_reply":"2022-04-22T14:57:15.097643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pygam import LogisticGAM, s, te\n\ngam = LogisticGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.099105Z","iopub.status.idle":"2022-04-22T14:57:15.099567Z","shell.execute_reply.started":"2022-04-22T14:57:15.09931Z","shell.execute_reply":"2022-04-22T14:57:15.099334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pygam import LogisticGAM, s, te\n\ngam = LinearGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.101081Z","iopub.status.idle":"2022-04-22T14:57:15.101561Z","shell.execute_reply.started":"2022-04-22T14:57:15.101298Z","shell.execute_reply":"2022-04-22T14:57:15.101323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pygam import PoissonGAM, s, te\n\ngam = PoissonGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\ny_pred = gam.predict(X_test)\ny_temp = y_pred > 0.5\nprint(accuracy_score(y_test, y_temp))\nprint(roc_auc_score(y_test, y_temp))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.104957Z","iopub.status.idle":"2022-04-22T14:57:15.105288Z","shell.execute_reply.started":"2022-04-22T14:57:15.105118Z","shell.execute_reply":"2022-04-22T14:57:15.105135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nclf1 = LinearGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\nclf1_prob = LinearGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\nclf2 = RandomForestClassifier(max_depth=50, random_state=1)\nclf3 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=6, random_state=0)\n\neclf_hard = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\neclf_soft = VotingClassifier(estimators=[('lr', clf1_prob), ('rf', clf2), ('gnb', clf3)],voting='soft')\n\nclf1 = clf1.fit(X_train, y_train)\nclf2 = clf2.fit(X_train, y_train)\nclf3 = clf3.fit(X_train, y_train)\neclf_hard = eclf_hard.fit(X_train, y_train)\neclf_soft = eclf_soft.fit(X_train, y_train)\n\nprint(\"GAM result:\")\ny_pred = clf1.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"RF result:\")\ny_pred = clf2.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"GBC results\")\ny_pred = clf3.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"hard voting result\")\ny_pred = eclf_hard.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"soft voting result\")\ny_pred = eclf_soft.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.106577Z","iopub.status.idle":"2022-04-22T14:57:15.106949Z","shell.execute_reply.started":"2022-04-22T14:57:15.106764Z","shell.execute_reply":"2022-04-22T14:57:15.106788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\n#clf1 = LinearGAM(s(0) + s(1) + s(2) + f(3)).fit(X_train, y_train)\n#clf1_prob = LinearGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\nclf2 = RandomForestClassifier(max_depth=50, random_state=1)\nclf3 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=6, random_state=0)\nclf4 = MLPClassifier(solver='adam', hidden_layer_sizes=(150,150, 150), random_state=1)\nclf5 = ExplainableBoostingClassifier(random_state=1)\n\neclf_hard = VotingClassifier(estimators=[('rf', clf2), ('gnb', clf3), (\"ebc\", clf5)],voting='hard')\neclf_soft = VotingClassifier(estimators=[('rf', clf2), ('gnb', clf3), (\"ebc\", clf5)],voting='soft')\n\n\neclf_hard = eclf_hard.fit(X_train, y_train)\neclf_soft = eclf_soft.fit(X_train, y_train)\n\nprint(\"hard voting result\")\ny_pred = eclf_hard.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"soft voting result\")\ny_pred = eclf_soft.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.107895Z","iopub.status.idle":"2022-04-22T14:57:15.108186Z","shell.execute_reply.started":"2022-04-22T14:57:15.10803Z","shell.execute_reply":"2022-04-22T14:57:15.108045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nclf1 = RandomForestClassifier(max_depth=57, random_state=0)\nclf2 = RandomForestClassifier(max_depth=68, random_state=0)\nclf3 = RandomForestClassifier(max_depth=66, random_state=0)\n\neclf_hard = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='hard')\neclf_soft = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='soft')\n\nclf1 = clf1.fit(X_train, y_train)\nclf2 = clf2.fit(X_train, y_train)\nclf3 = clf3.fit(X_train, y_train)\neclf_hard = eclf_hard.fit(X_train, y_train)\neclf_soft = eclf_soft.fit(X_train, y_train)\n\nprint(\"SVM result:\")\ny_pred = clf1.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"RF result:\")\ny_pred = clf2.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"MLP results\")\ny_pred = clf3.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"hard voting result\")\ny_pred = eclf_hard.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\n\nprint(\"soft voting result\")\ny_pred = eclf_soft.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.109175Z","iopub.status.idle":"2022-04-22T14:57:15.109494Z","shell.execute_reply.started":"2022-04-22T14:57:15.109336Z","shell.execute_reply":"2022-04-22T14:57:15.109352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances = pd.DataFrame(best_model.feature_importances_,index = list(X.columns), columns=['importance']).sort_values('importance', ascending=False)\nprint(feature_importances)\n\ntop_5 = feature_importances.head(5).index\ntop_10 = feature_importances.head(10).index\ntop_15 = feature_importances.head(15).index\ntop_20 = feature_importances.head(20).index\ntop_25 = feature_importances.head(25).index\ntop_30 = feature_importances.head(30).index\ntop_35 = feature_importances.head(35).index\ntop_40 = feature_importances.head(40).index\ntop_45 = feature_importances.head(45).index\ntop_50 = feature_importances.head(50).index\ntop_features = [top_5, top_10, top_15, top_20, top_25,top_30, top_35,top_40, top_45, top_50]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:06:08.248244Z","iopub.execute_input":"2022-04-24T19:06:08.248554Z","iopub.status.idle":"2022-04-24T19:06:08.290108Z","shell.execute_reply.started":"2022-04-24T19:06:08.248517Z","shell.execute_reply":"2022-04-24T19:06:08.289073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_AUC_rf = 0\nbest_model_rf = None\n\ntop_AUC_svm = 0\nbest_model_svm = None\n\ntop_AUC_gbc = 0\nbest_model_gbc = None\n\ntop_AUC_knn = 0\nbest_model_knn = None\n\ntop_AUC_ada = 0\nbest_model_ada = None\n\ntop_AUC_mlp = 0\nbest_model_mlp = None\n\nfor element in top_features:\n    # define dataset\n    X = df[element]\n    y = df[\"HOSPITAL_EXPIRE_FLAG\"]\n    sm = SMOTE(random_state=42)\n    X_res, y_res = sm.fit_resample(X, y)\n    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state = 1)\n    # define pipeline\n    \"\"\"k = 1\n    while k < len(element) and k < 35:\n    # define pipeline\n        print(\"random forest results for:\" + str(len(element)))\n        # evaluate pipeline\n        model = RandomForestClassifier(max_depth=k, random_state=0)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(k)\n        print(accuracy_score(y_test, y_pred))\n        print(roc_auc_score(y_test, y_pred))\n        k = k + 1\n        if roc_auc_score(y_test, y_pred) > top_AUC_rf:\n            top_AUC_rf = roc_auc_score(y_test, y_pred)\n            best_model_rf = model\n            \n    print(\"SVM results\")\n    k = 1\n    while k < 8:\n        # evaluate pipeline\n        model = SVC(degree=k)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(k)\n        print(accuracy_score(y_test, y_pred))\n        print(roc_auc_score(y_test, y_pred))\n        k = k + 1\n        if roc_auc_score(y_test, y_pred) > top_AUC_svm:\n            top_AUC_svm = roc_auc_score(y_test, y_pred)\n            best_model_svm = model\n\n    print(\"GradientBoostingClassifier results\")\n    k = 1\n    while k < 7:\n        # evaluate pipeline\n        model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=k, random_state=0)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(k)\n        print(accuracy_score(y_test, y_pred))\n        print(roc_auc_score(y_test, y_pred))\n        k = k + 1\n        if roc_auc_score(y_test, y_pred) > top_AUC_gbc:\n            top_AUC_gbc = roc_auc_score(y_test, y_pred)\n            best_model_gbc = model\n\n    print(\"AdaBoostClassifier results\")\n    k = 15\n    while k < 20:\n        # evaluate pipeline\n        model = AdaBoostClassifier(n_estimators=k*25, random_state=0)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(k)\n        print(accuracy_score(y_test, y_pred))\n        print(roc_auc_score(y_test, y_pred))\n        k = k + 1\n        if roc_auc_score(y_test, y_pred) > top_AUC_ada:\n            top_AUC_ada = roc_auc_score(y_test, y_pred)\n            best_model_ada = model\n\n    print(\"Knn results\")\n    k = 3\n    while k < 10:\n        # evaluate pipeline\n        model = KNeighborsClassifier(n_neighbors=k)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(k)\n        print(accuracy_score(y_test, y_pred))\n        print(roc_auc_score(y_test, y_pred))\n        k = k + 1\n        if roc_auc_score(y_test, y_pred) > top_AUC_knn:\n            top_AUC_knn = roc_auc_score(y_test, y_pred)\n            best_model_knn = model\n\n    print(\"MLP results\")\n    k = 1\n    while k < 8:\n        # evaluate pipeline\n        model = MLPClassifier(solver='adam', hidden_layer_sizes=(25*k,25*k, 25*k), random_state=1)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        print(k)\n        print(accuracy_score(y_test, y_pred))\n        print(roc_auc_score(y_test, y_pred))\n        k = k + 1\n        if roc_auc_score(y_test, y_pred) > top_AUC_mlp:\n            top_AUC_mlp = roc_auc_score(y_test, y_pred)\n            best_model_mlp = model\n    \"\"\"\n    from interpret import set_visualize_provider\n    from interpret.provider import InlineProvider\n    set_visualize_provider(InlineProvider())\n\n    from interpret.glassbox import ExplainableBoostingClassifier\n    from interpret import show\n\n    ebm = ExplainableBoostingClassifier(random_state=1)\n    ebm.fit(X_train, y_train)\n    y_pred = ebm.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    \n    \"\"\"try:\n        gam = LinearGAM(s(0) + s(1) + f(2)).fit(X_train, y_train)\n        y_pred = gam.predict(X_test)\n        y_temp = y_pred > 0.5\n        print(accuracy_score(y_test, y_temp))\n        print(roc_auc_score(y_test, y_temp))\n    except:\n        gam = LinearGAM(s(0) + s(1) + s(2) + f(3)).fit(X_train, y_train)\n        y_pred = gam.predict(X_test)\n        y_temp = y_pred > 0.5\n        print(accuracy_score(y_test, y_temp))\n        print(roc_auc_score(y_test, y_temp))\"\"\"\n    print(\"done:\" + str(element))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:47:54.839926Z","iopub.execute_input":"2022-04-24T17:47:54.840196Z","iopub.status.idle":"2022-04-24T17:51:56.555597Z","shell.execute_reply.started":"2022-04-24T17:47:54.840161Z","shell.execute_reply":"2022-04-24T17:51:56.554706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for element in top_features:\n    # define dataset\n    X = df[element]\n    X = df[top_15]\n    y = df[\"HOSPITAL_EXPIRE_FLAG\"]\n    sm = SMOTE(random_state=42)\n    X_res, y_res = sm.fit_resample(X, y)\n    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n    # define pipeline\n    ebm1 = ExplainableBoostingClassifier(random_state=1)\n\n\n    ebm2 = ExplainableBoostingClassifier(random_state=2)\n\n\n    ebm3 = ExplainableBoostingClassifier(random_state=3)\n\n\n\n\n    from sklearn.ensemble import VotingClassifier\n\n    eclf_hard = VotingClassifier(estimators=[('rf', ebm1), ('gnb', ebm2), (\"ebc\", ebm3)],voting='hard')\n    eclf_soft = VotingClassifier(estimators=[('rf', ebm1), ('gnb', ebm2), (\"ebc\", ebm3)],voting='soft')\n\n\n    eclf_hard = eclf_hard.fit(X_train, y_train)\n    eclf_soft = eclf_soft.fit(X_train, y_train)\n\n    print(\"hard voting result\")\n    y_pred = eclf_hard.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n\n    print(\"soft voting result\")\n    y_pred = eclf_soft.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n\n    ebm1.fit(X_train, y_train)\n    y_pred = ebm1.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n\n    ebm2.fit(X_train, y_train)\n    y_pred = ebm2.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n\n    ebm3.fit(X_train, y_train)\n    y_pred = ebm3.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:00:25.851761Z","iopub.status.idle":"2022-04-24T19:00:25.852074Z","shell.execute_reply.started":"2022-04-24T19:00:25.851902Z","shell.execute_reply":"2022-04-24T19:00:25.851931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances = pd.DataFrame(best_model.feature_importances_,index = list(feature_importances.head(40).index), columns=['importance']).sort_values('importance', ascending=False)\nprint(feature_importances['importance'].to_numpy().size)\nprint(feature_importances)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.113581Z","iopub.status.idle":"2022-04-22T14:57:15.11392Z","shell.execute_reply.started":"2022-04-22T14:57:15.113757Z","shell.execute_reply":"2022-04-22T14:57:15.113774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[top_15]                                      ","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:09:35.681379Z","iopub.execute_input":"2022-04-24T19:09:35.681661Z","iopub.status.idle":"2022-04-24T19:09:35.710488Z","shell.execute_reply.started":"2022-04-24T19:09:35.681633Z","shell.execute_reply":"2022-04-24T19:09:35.709438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from interpret import set_visualize_provider\nfrom interpret.provider import InlineProvider\nset_visualize_provider(InlineProvider())\n\nfrom interpret.glassbox import ExplainableBoostingClassifier\nfrom interpret import show\n\nX = df[element]\nX = df[top_15]\ny = df[\"HOSPITAL_EXPIRE_FLAG\"]\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state = 1)\n    # define pipeline\nebm1 = ExplainableBoostingClassifier(random_state=1)\nebm1.fit(X_train, y_train)\ny_pred = ebm1.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(roc_auc_score(y_test, y_pred))\nebm1_global = ebm1.explain_global()\nshow(ebm1_global)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T19:09:11.595656Z","iopub.execute_input":"2022-04-24T19:09:11.596771Z","iopub.status.idle":"2022-04-24T19:09:27.647429Z","shell.execute_reply.started":"2022-04-24T19:09:11.59671Z","shell.execute_reply":"2022-04-24T19:09:27.646328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[:50]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:56:44.732701Z","iopub.execute_input":"2022-04-22T16:56:44.733883Z","iopub.status.idle":"2022-04-22T16:56:44.792983Z","shell.execute_reply.started":"2022-04-22T16:56:44.733834Z","shell.execute_reply":"2022-04-22T16:56:44.79195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ebm1_local = ebm1.explain_local(X_test[:50], y_test[:50])\nshow(ebm1_local)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:49:29.669593Z","iopub.execute_input":"2022-04-22T16:49:29.670277Z","iopub.status.idle":"2022-04-22T16:49:30.001077Z","shell.execute_reply.started":"2022-04-22T16:49:29.670235Z","shell.execute_reply":"2022-04-22T16:49:30.000266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset not changes\n\nfrom matplotlib import pyplot\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n# define dataset\nX = df.drop([\"HOSPITAL_EXPIRE_FLAG\"], axis=1)\ny = df[\"HOSPITAL_EXPIRE_FLAG\"]\n#sm = SMOTE(random_state=42)\n#X_res, y_res = sm.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n# define pipeline\nk = 1\nprint(\"random forest results\")\nwhile k < 35:\n    # evaluate pipeline\n    model = RandomForestClassifier(max_depth=k, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n\nprint(\"SVM results\")\nk = 1\nwhile k < 8:\n    # evaluate pipeline\n    model = SVC(degree=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"GradientBoostingClassifier results\")\nk = 1\nwhile k < 7:\n    # evaluate pipeline\n    model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=k, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"AdaBoostClassifier results\")\nk = 1\nwhile k < 7:\n    # evaluate pipeline\n    model = AdaBoostClassifier(n_estimators=k*25, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"Knn results\")\nk = 3\nwhile k < 10:\n    # evaluate pipeline\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"MLP results\")\nk = 1\nwhile k < 10:\n    # evaluate pipeline\n    model = MLPClassifier(solver='adam', hidden_layer_sizes=(10*k,10*k, 10*k), random_state=1)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.114901Z","iopub.status.idle":"2022-04-22T14:57:15.115197Z","shell.execute_reply.started":"2022-04-22T14:57:15.115039Z","shell.execute_reply":"2022-04-22T14:57:15.115054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset randomundersampling\n\nfrom matplotlib import pyplot\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n# define dataset\nX = df.drop([\"HOSPITAL_EXPIRE_FLAG\"], axis=1)\ny = df[\"HOSPITAL_EXPIRE_FLAG\"]\nrus = RandomUnderSampler(random_state=42)\nX_res, y_res = rus.fit_resample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n# define pipeline\nk = 1\nprint(\"random forest results\")\nwhile k < 35:\n    # evaluate pipeline\n    model = RandomForestClassifier(max_depth=k, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n\nprint(\"SVM results\")\nk = 1\nwhile k < 8:\n    # evaluate pipeline\n    model = SVC(degree=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"GradientBoostingClassifier results\")\nk = 1\nwhile k < 7:\n    # evaluate pipeline\n    model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=k, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"AdaBoostClassifier results\")\nk = 1\nwhile k < 7:\n    # evaluate pipeline\n    model = AdaBoostClassifier(n_estimators=k*25, random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"Knn results\")\nk = 3\nwhile k < 10:\n    # evaluate pipeline\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1\n    \nprint(\"MLP results\")\nk = 1\nwhile k < 10:\n    # evaluate pipeline\n    model = MLPClassifier(solver='adam', hidden_layer_sizes=(10*k,10*k, 10*k), random_state=1)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(k)\n    print(accuracy_score(y_test, y_pred))\n    print(roc_auc_score(y_test, y_pred))\n    k = k + 1","metadata":{"execution":{"iopub.status.busy":"2022-04-22T14:57:15.115911Z","iopub.status.idle":"2022-04-22T14:57:15.116202Z","shell.execute_reply.started":"2022-04-22T14:57:15.116047Z","shell.execute_reply":"2022-04-22T14:57:15.116062Z"},"trusted":true},"execution_count":null,"outputs":[]}]}